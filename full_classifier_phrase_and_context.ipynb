{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с классификатором"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /.local/lib/python3.6/site-packages (1.10.2)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /.local/lib/python3.6/site-packages (4.18.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from transformers) (4.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /.local/lib/python3.6/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: sacremoses in /.local/lib/python3.6/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: filelock in /.local/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /.local/lib/python3.6/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /.local/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /.local/lib/python3.6/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.6/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /.local/lib/python3.6/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow in /.local/lib/python3.6/site-packages (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ[\"SENTENCE_TRANSFORMERS_HOME\"] = os.path.abspath(\"./.cache\")\n",
    "os.environ[\"TORCH_HOME\"] = os.path.abspath(\"./.cache\")\n",
    "os.environ[\"HF_HOME\"] = os.path.abspath(\"./.cache\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = os.path.abspath(\"./.cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./train2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "      <th>context_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ну куда пошли</td>\n",
       "      <td>[{'user': '', 'marusia': ''}, {'user': '', 'ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>а сколько будет миллиард долларов рублей</td>\n",
       "      <td>[{'user': 'а сколько будет', 'marusia': 'Извин...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>user: а сколько будет. marusia: Извините, я н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>марусь включи пожалуйста елена вальяк гипноз д...</td>\n",
       "      <td>[{'user': 'маруся через десять минут будильник...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>user: маруся через десять минут будильник вкл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>да о том что я тебя очень уважаю люблю</td>\n",
       "      <td>[{'user': '', 'marusia': 'Если вам нужна помощ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>marusia: Если вам нужна помощь, я к вашим усл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>детскую песенку</td>\n",
       "      <td>[{'user': '', 'marusia': ''}, {'user': 'угадай...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>user: угадай такую загадку мою загадку кто тв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28899</th>\n",
       "      <td>так где мой нож</td>\n",
       "      <td>[{'user': '', 'marusia': ''}, {'user': 'ты уме...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>user: ты умеешь материться. marusia: Перцептр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28900</th>\n",
       "      <td>дальше</td>\n",
       "      <td>[{'user': '', 'marusia': ''}, {'user': '', 'ma...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>user: включи сказку колобок. marusia: Слушаем...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28901</th>\n",
       "      <td>маруся я очень тебя люблю</td>\n",
       "      <td>[{'user': 'маруся очень очень я тебя люблю', '...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>user: маруся очень очень я тебя люблю. marusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28902</th>\n",
       "      <td>голову вас зафиксировала камера</td>\n",
       "      <td>[{'user': '', 'marusia': ''}, {'user': 'ну дав...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>user: ну давай. marusia: Вы на что намекаете?.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28903</th>\n",
       "      <td>что представляем</td>\n",
       "      <td>[{'user': 'ты вообще не можешь', 'marusia': 'В...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>user: ты вообще не можешь. marusia: Вы что! я...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28904 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  phrase  \\\n",
       "0                                          ну куда пошли   \n",
       "1               а сколько будет миллиард долларов рублей   \n",
       "2      марусь включи пожалуйста елена вальяк гипноз д...   \n",
       "3                 да о том что я тебя очень уважаю люблю   \n",
       "4                                        детскую песенку   \n",
       "...                                                  ...   \n",
       "28899                                    так где мой нож   \n",
       "28900                                             дальше   \n",
       "28901                          маруся я очень тебя люблю   \n",
       "28902                    голову вас зафиксировала камера   \n",
       "28903                                   что представляем   \n",
       "\n",
       "                                                 context  target  \\\n",
       "0      [{'user': '', 'marusia': ''}, {'user': '', 'ma...     1.0   \n",
       "1      [{'user': 'а сколько будет', 'marusia': 'Извин...     0.0   \n",
       "2      [{'user': 'маруся через десять минут будильник...     0.0   \n",
       "3      [{'user': '', 'marusia': 'Если вам нужна помощ...     0.0   \n",
       "4      [{'user': '', 'marusia': ''}, {'user': 'угадай...     0.0   \n",
       "...                                                  ...     ...   \n",
       "28899  [{'user': '', 'marusia': ''}, {'user': 'ты уме...     1.0   \n",
       "28900  [{'user': '', 'marusia': ''}, {'user': '', 'ma...     0.0   \n",
       "28901  [{'user': 'маруся очень очень я тебя люблю', '...     0.0   \n",
       "28902  [{'user': '', 'marusia': ''}, {'user': 'ну дав...     1.0   \n",
       "28903  [{'user': 'ты вообще не можешь', 'marusia': 'В...     0.0   \n",
       "\n",
       "                                            context_text  \n",
       "0                                                         \n",
       "1       user: а сколько будет. marusia: Извините, я н...  \n",
       "2       user: маруся через десять минут будильник вкл...  \n",
       "3       marusia: Если вам нужна помощь, я к вашим усл...  \n",
       "4       user: угадай такую загадку мою загадку кто тв...  \n",
       "...                                                  ...  \n",
       "28899   user: ты умеешь материться. marusia: Перцептр...  \n",
       "28900   user: включи сказку колобок. marusia: Слушаем...  \n",
       "28901   user: маруся очень очень я тебя люблю. marusi...  \n",
       "28902    user: ну давай. marusia: Вы на что намекаете?.   \n",
       "28903   user: ты вообще не можешь. marusia: Вы что! я...  \n",
       "\n",
       "[28904 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['context_text'].fillna('', inplace=True)\n",
    "data['phrase'].fillna('', inplace=True)\n",
    "data['target'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import transformers\n",
    "#transformers.utils.logging.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/distilrubert-base-cased-conversational were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# \"sberbank-ai/ruRoberta-large\"\n",
    "# \"DeepPavlov/distilrubert-base-cased-conversational\"\n",
    "# \"xlm-roberta-base\"\n",
    "model_name = \"DeepPavlov/distilrubert-base-cased-conversational\"\n",
    "main_model = AutoModel.from_pretrained(model_name)\n",
    "main_tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = main_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-ks6qv0sr because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_context_text, test_context_text, train_phrase, test_phrase, train_target, test_target = train_test_split(\n",
    "    data['context_text'].tolist(),\n",
    "    data['phrase'].tolist(),\n",
    "    torch.tensor(data['target'].to_numpy(), dtype=torch.float32).to(device),\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' user: в смысле тут. marusia: Да, где ж еще?. user: в смысле в казахстане. marusia:  Значение слова КАЗАХСТАН. Что такое КАЗАХСТАН?: Қазақстан [qɑzɑqˈstɑn]), официально Респу́блика Казахста́н - государство в центре Евразии, бо́льшая часть которого относится к Азии, меньшая - к Европе..., symbols cut: 95. user: один. marusia: Один? почему один. user: два. marusia: Сапога пара. user: вот смешно. marusia: Очень смешно. Продолжайте нас веселить. '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_context_text[4242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextPhraseDataset(Dataset):\n",
    "    def __init__(self, contexts, phrases, targets):\n",
    "        assert len(contexts) == len(phrases) == len(targets)\n",
    "        \n",
    "        self.contexts = contexts\n",
    "        self.phrases = phrases\n",
    "        self.targets = targets\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.contexts[idx], self.phrases[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_dataset = ContextPhraseDataset(train_context_text, train_phrase, train_target)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Test\n",
    "test_dataset = ContextPhraseDataset(test_context_text, test_phrase, test_target)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_on_texts(tokenizer, model, dataloader, only_phrase=True):\n",
    "    full_proba = []\n",
    "    full_y = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            context, phrase, y = batch\n",
    "            full_y.append(y.cpu().detach().numpy())\n",
    "            \n",
    "            context = list(context)\n",
    "            phrase = list(phrase)\n",
    "            \n",
    "            phrase_tokens = tokenizer(phrase, padding=True, truncation='only_first',\n",
    "                                      return_tensors=\"pt\").to(device)\n",
    "            \n",
    "            if only_phrase:\n",
    "                full_proba.append(model(phrase_tokens).cpu().detach().numpy())\n",
    "            else:\n",
    "                context_tokens = tokenizer(context, padding=True, truncation='only_first',\n",
    "                                       return_tensors=\"pt\").to(device)\n",
    "                \n",
    "                full_proba.append(model(context_tokens, phrase_tokens).cpu().detach().numpy())\n",
    "            \n",
    "    full_proba = np.concatenate(full_proba)\n",
    "    full_y = np.concatenate(full_y).astype(np.int32)\n",
    "            \n",
    "    return full_proba, full_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhraseModel(torch.nn.Module):\n",
    "    def __init__(self, language_model, hid_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.language_model = language_model\n",
    "        self.linear_1 = torch.nn.Linear(2 * hid_size, 2 * hid_size)\n",
    "        self.linear_2 = torch.nn.Linear(2 * hid_size, 1)\n",
    "        \n",
    "        self.leaky_relu = torch.nn.LeakyReLU()\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, context_tokens, phrase_tokens):        \n",
    "        context_embeddings = self.language_model(**context_tokens)[\"last_hidden_state\"][:,-1,:]\n",
    "        phrase_embeddings = self.language_model(**phrase_tokens)[\"last_hidden_state\"][:,-1,:]\n",
    "        \n",
    "        x = torch.cat([context_embeddings, phrase_embeddings], axis=-1)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        \n",
    "        return self.activation(torch.squeeze(x, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_model = PhraseModel(main_model, hid_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in main_model.parameters():\n",
    "    params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.BCELoss()\n",
    "opt = torch.optim.Adam(phrase_model.parameters(), lr=7.5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'train_loss': [], 'roc_auc': [], 'f1_score': []}\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    avg_loss = 0.0\n",
    "    for index, batch in enumerate(tqdm(train_dataloader)):\n",
    "        context, phrase, y = batch\n",
    "        context = list(context)\n",
    "        phrase = list(phrase)\n",
    "        context_tokens = main_tokenizer(context, padding=True, truncation='only_first',\n",
    "                                        return_tensors=\"pt\").to(device)\n",
    "        phrase_tokens = main_tokenizer(phrase, padding=True, truncation='only_first',\n",
    "                                       return_tensors=\"pt\").to(device)\n",
    "        proba = phrase_model(context_tokens, phrase_tokens)\n",
    "\n",
    "        del phrase_tokens\n",
    "        loss_t = loss(input=proba, target=y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "\n",
    "        avg_loss += loss_t.item()\n",
    "\n",
    "    avg_loss /= index\n",
    "    metrics['train_loss'].append((epoch, avg_loss))\n",
    "\n",
    "    if True: #epoch % 5 == 0:\n",
    "        full_proba, full_y = inference_on_texts(main_tokenizer, phrase_model, test_dataloader, only_phrase=False)\n",
    "        \n",
    "        metrics['roc_auc'].append((epoch, roc_auc_score(full_y, full_proba)))\n",
    "        metrics['f1_score'].append((epoch, f1_score(full_y, full_proba > 0.15)))\n",
    "\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(12,4))\n",
    "        for i, (name, history) in enumerate(sorted(metrics.items())):\n",
    "            plt.subplot(1, len(metrics), i + 1)\n",
    "            plt.title(name)\n",
    "            plt.plot(*zip(*history))\n",
    "            plt.grid()\n",
    "        plt.show()\n",
    "        print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-1:], axis=0)[1], flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_proba, full_y = inference_on_texts(main_tokenizer, phrase_model, test_dataloader, only_phrase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final ROC AUC: {roc_auc_score(full_y, full_proba):.3f}\")\n",
    "print(f\"Final F1: {f1_score(full_y, full_proba > 0.15):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение на всём датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"./test3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(test_data_path, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>id</th>\n",
       "      <th>context_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>еще</td>\n",
       "      <td>1</td>\n",
       "      <td>user: еще одну. marusia: Забавной обезьяне бр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>точно точно он добрый</td>\n",
       "      <td>2</td>\n",
       "      <td>user: у тебя все нормально. marusia: Со мной ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ты всегда права и у тебя есть права</td>\n",
       "      <td>3</td>\n",
       "      <td>user: отлично я теперь тоже спокойно. marusia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>маруся так ты же вышла автобус уезжает на друг...</td>\n",
       "      <td>4</td>\n",
       "      <td>user: маруся скажи. marusia: Маруся. user: ма...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>научи меня читать</td>\n",
       "      <td>5</td>\n",
       "      <td>user: сорок. marusia: Замечательно! 10 на 4?....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>а я вас</td>\n",
       "      <td>7114</td>\n",
       "      <td>user: я прыгаю от счастья. marusia: Супер мил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7114</th>\n",
       "      <td>маруся она где</td>\n",
       "      <td>7115</td>\n",
       "      <td>user: а во что ты очень сильно любишь играть....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7115</th>\n",
       "      <td>не знаю не отвечает почему то</td>\n",
       "      <td>7116</td>\n",
       "      <td>user: привет маруся. marusia: Здравствуйте!. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7116</th>\n",
       "      <td>давай музыку</td>\n",
       "      <td>7117</td>\n",
       "      <td>user: маруся пока маруся спокойной ночи марус...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117</th>\n",
       "      <td>извините это не тебя</td>\n",
       "      <td>7118</td>\n",
       "      <td>user: маруся как меня зовут. marusia: Khusnid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase    id  \\\n",
       "0                                                   еще     1   \n",
       "1                                 точно точно он добрый     2   \n",
       "2                   ты всегда права и у тебя есть права     3   \n",
       "3     маруся так ты же вышла автобус уезжает на друг...     4   \n",
       "4                                     научи меня читать     5   \n",
       "...                                                 ...   ...   \n",
       "7113                                            а я вас  7114   \n",
       "7114                                     маруся она где  7115   \n",
       "7115                      не знаю не отвечает почему то  7116   \n",
       "7116                                       давай музыку  7117   \n",
       "7117                               извините это не тебя  7118   \n",
       "\n",
       "                                           context_text  \n",
       "0      user: еще одну. marusia: Забавной обезьяне бр...  \n",
       "1      user: у тебя все нормально. marusia: Со мной ...  \n",
       "2      user: отлично я теперь тоже спокойно. marusia...  \n",
       "3      user: маруся скажи. marusia: Маруся. user: ма...  \n",
       "4      user: сорок. marusia: Замечательно! 10 на 4?....  \n",
       "...                                                 ...  \n",
       "7113   user: я прыгаю от счастья. marusia: Супер мил...  \n",
       "7114   user: а во что ты очень сильно любишь играть....  \n",
       "7115   user: привет маруся. marusia: Здравствуйте!. ...  \n",
       "7116   user: маруся пока маруся спокойной ночи марус...  \n",
       "7117   user: маруся как меня зовут. marusia: Khusnid...  \n",
       "\n",
       "[7118 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['context_text'].fillna('', inplace=True)\n",
    "test_data['phrase'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = ContextPhraseDataset(data['context_text'].tolist(), data['phrase'].tolist(), torch.tensor(data['target'].to_numpy(), dtype=torch.float32).to(device))\n",
    "full_dataloader = DataLoader(full_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "final_test_dataset = ContextPhraseDataset(test_data['context_text'].to_list(), test_data['phrase'].to_list(), torch.tensor(test_data['id'].to_numpy(), dtype=torch.int32).to(device))\n",
    "final_test_dataloader = DataLoader(final_test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [01:00<00:00, 14.80it/s]\n"
     ]
    }
   ],
   "source": [
    "full_proba, full_y = inference_on_texts(main_tokenizer, phrase_model, final_test_dataloader, only_phrase=False)\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = full_y\n",
    "submission['target'] = full_proba\n",
    "    \n",
    "submission.to_csv(\"sub\" + str(0) + \".csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 266/7226 [00:39<18:16,  6.35it/s]"
     ]
    }
   ],
   "source": [
    "metrics = {'train_loss': [], 'roc_auc': [], 'f1_score': []}\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(5, n_epochs+1):\n",
    "    avg_loss = 0.0\n",
    "    for index, batch in enumerate(tqdm(full_dataloader)):\n",
    "        context, phrase, y = batch\n",
    "        context = list(context)\n",
    "        phrase = list(phrase)\n",
    "        context_tokens = main_tokenizer(context, padding=True, truncation='only_first',\n",
    "                                        return_tensors=\"pt\").to(device)\n",
    "        phrase_tokens = main_tokenizer(phrase, padding=True, truncation='only_first',\n",
    "                                       return_tensors=\"pt\").to(device)\n",
    "        proba = phrase_model(context_tokens, phrase_tokens)\n",
    "\n",
    "        del phrase_tokens\n",
    "        loss_t = loss(input=proba, target=y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "\n",
    "        avg_loss += loss_t.item()\n",
    "\n",
    "    avg_loss /= index\n",
    "    metrics['train_loss'].append((epoch, avg_loss))\n",
    "    print(metrics['train_loss'])\n",
    "    \n",
    "    full_proba, full_y = inference_on_texts(main_tokenizer, phrase_model, final_test_dataloader, only_phrase=False)\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id'] = full_y\n",
    "    submission['target'] = full_proba\n",
    "\n",
    "    submission.to_csv(\"sub\" + str(epoch) + \".csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
